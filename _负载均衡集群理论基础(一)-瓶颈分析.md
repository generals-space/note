# 负载均衡集群理论基础(一)-瓶颈分析

初涉运维, 对很多东西还没有系统的了解, 这里的想法可能在不久以后被推翻. 暂作为阶段性的笔记, 并不能保证准确性.

负载均衡应该算是性能调优的一种手段. 单台服务器无法满足项目需求, 只能以集群形式分散压力.

然而任何形式的架构都不会完美存在, 集群也依然存在瓶颈.

## 1. 独立服务器

首先, 单台服务器存在瓶颈, 在于程序执行计算任务的速度(比如传输压缩), 与客户端建立的连接数目, 数据库查询时间等. 而这些归根究底还是要追溯到硬件层面, 可能局限于CPU个数, 内存大小, 硬盘读写速度等(当然这是在假设带宽, 流量富余的情况下).

理论上, 只要CPU足够多, 内存足够大, 硬盘足够快... 单台服务器足以应付所有请求. 然而

1. 服务器的硬件无法无限升级或附加, 硬件技术和成本会限制你的选择(就算可以, 也总会存在短板成为新的瓶颈);

2. 另一方面, 内存, 硬盘过大过快, 系统应用于内存管理和磁盘管理, 保证数据准确的开销也将会更大;

3. 再者, 服务器软件也不一定能完全发挥高配硬件的性能(像Tomcat, 4G 双核的配置却无法达到1000并发的情况也不是没有, Tomcat对硬件的使用率太低了).

性能曲线总存在那么一个峰值, 过犹不及;

## 2. 服务器集群

关于负载均衡集群, 架构一般如下:

![](http://img.generals.space/0ee734d4d7c996dcadb03d9dc18e5ab3.png)

集群的瓶颈应该就是并发连接数. Nginx炙手可热的原因就是其支持高并发且性能优异.

------

理论上讲只要后端服务器足够多, 无论多少请求都来者不拒, 然而瓶颈依然存在.

前端服务器需要建立与客户端的成千上万的连接(并维持), 同时监测后端服务器群的运行状态, 按照指定算法将请求转发, 有可能其所在服务器还需要维护持久session, 这已经是不小的开销.

于是前端服务器可以再分层, 层层分发(监测几台后端负载均衡服务器的状态总比监测数十上百台后端应用服务器来的轻松吧). 有时为了保证高可用性会为前端服务器配置备机. 结构大致如下:

![](http://img.generals.space/be6c0b7804ad266a61eed96ac031ac5c.png)

但是备机与主机一般共享同一个IP, 所以最前端同时运行的依然只能有一台服务器.

到此, 又成了单台服务器, 瓶颈又回到硬件, 这是一个死结.

于是最前端服务器在有限资源下能够维持的连接数将成为集群架构中最大的瓶颈, 如果无法保证此项, 后端服务器群的规模再大也将无用武之地. 这也是高并发服务器深受追捧的原因, Nginx的高并发且高性能可以大展身手.